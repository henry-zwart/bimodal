{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1518fd82-19ac-45af-a170-79025e1ca90d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4027a03-158f-44b5-ab60-6c469797b3a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = Path(\"../data/raw_counter\")\n",
    "CLEAN_DATA_PATH = Path(\"../data/clean_counter\")\n",
    "\n",
    "YEAR_FILES = {\n",
    "    2018: Path(\"2018_ecocounter_data_20230905140019.csv\"),\n",
    "    2019: Path(\"2019_ecocounter_data_20230905140408.csv\"),\n",
    "    2020: Path(\"2020_ecocounter_data_20230905140803.csv\"),\n",
    "    2021: Path(\"2021_ecocounter_data_20230905141200.csv\"),\n",
    "    2022: Path(\"2022_ecocounter_data_20230905141557.csv\"),\n",
    "    2023: Path(\"2023_ecocounter_data_20230905141951.csv\"),\n",
    "}\n",
    "\n",
    "RENAME_MAPPING = {\n",
    "    \"Site ID\": \"site_id\",\n",
    "    \"Site name\": \"site_name\",\n",
    "    \"Date/time\": \"record_time\",\n",
    "    \"Incoming count\": \"count_incoming\",\n",
    "    \"Outgoing count\": \"count_outgoing\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5b579a-81d5-4070-a393-5933588dbcfd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "**Data issues**\n",
    "- \"Count\" columns are sometimes integer, sometimes string\n",
    "- \"Count\" columns can contain nulls\n",
    "- Current year contains future dates, prepopulated with Null\n",
    "- Each (location,datetime) pair has two rows, for incoming and outgoing counts\n",
    "\n",
    "**Cleaning**\n",
    "1. Select incoming data rows where outgoing data is equal to zero. This eliminates null rows and those where the count is obviously in the other direction\n",
    "2. Select the maximum count value per (location, datetime) pair\n",
    "3. Repeat for outgoing data\n",
    "4. Drop the incoming and outgoing data cols from the original dataframe, and uniquify the the rows to eliminate duplicate (location, datetime) pairs\n",
    "5. Left going against the incoming and outgoing data rows.\n",
    "\n",
    "This deduplicates the rows, ensuring each (location, datetime) occurs in exactly one row, and that the incoming and outgoing counts exist on the same row, while preserving the null information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f2e785-6cef-42f9-8b39-f822cd3da355",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for year, yf in YEAR_FILES.items():\n",
    "    data = (\n",
    "        pl.read_csv(RAW_DATA_PATH / yf)\n",
    "        .with_columns(pl.col(\"^.* count$\").cast(pl.Int64))\n",
    "    )\n",
    "    incoming_data = (\n",
    "        data\n",
    "        .filter(\n",
    "            (pl.col(\"Incoming count\").is_not_null()) & \n",
    "            (pl.col(\"Outgoing count\") == 0)\n",
    "        )\n",
    "        .drop(\"Outgoing count\")\n",
    "        .lazy()\n",
    "        .groupby([\"Site ID\", \"Site name\", \"Date/time\"])\n",
    "        .max()\n",
    "        .collect()\n",
    "    )\n",
    "    outgoing_data = (\n",
    "        data\n",
    "        .filter(\n",
    "            (pl.col(\"Outgoing count\").is_not_null()) & \n",
    "            (pl.col(\"Incoming count\") == 0)\n",
    "        )\n",
    "        .drop(\"Incoming count\")\n",
    "        .lazy()\n",
    "        .groupby([\"Site ID\", \"Site name\", \"Date/time\"])\n",
    "        .max()\n",
    "        .collect()\n",
    "    )\n",
    "    cleaned_data = (\n",
    "        data\n",
    "        .drop(\"Incoming count\", \"Outgoing count\")\n",
    "        .unique(maintain_order=True)\n",
    "        .join(incoming_data, on=[\"Site ID\", \"Site name\", \"Date/time\"], how=\"left\")\n",
    "        .join(outgoing_data, on=[\"Site ID\", \"Site name\", \"Date/time\"], how=\"left\")\n",
    "        .rename(RENAME_MAPPING)\n",
    "    )\n",
    "    cleaned_data.write_csv(CLEAN_DATA_PATH / yf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80288337-ec88-479a-bfd9-9315d05739bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afda500-4a64-48e1-87ca-c0ab033b67c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_data = cleaned_data.with_columns(\n",
    "    pl.col(\"record_time\").str.to_datetime()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f976c82a-a4f1-4c4e-8bae-9f2544a008aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_data.filter(\n",
    "    (pl.col(\"record_time\").dt.year() == 2022) &\n",
    "    (pl.col(\"site_name\") == \"Basin Reserve\") & \n",
    "    (pl.col(\"record_time\").dt.month() == 8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d8764d-b489-41e2-a44d-ae739bb99747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
